import logging
import os

import pandas as pd
from PySide6.QtCore import QObject, Signal, Slot
from sb3_contrib import MaskablePPO
from stable_baselines3.common.logger import configure

from modules.algo_trade import AlgoTrade
from modules.env import TrainingEnv, TradingEnv
from structs.app_enum import ActionType, PositionType


class MaskablePPOAgent:
    def __init__(self):
        super().__init__()
        self.env = None
        # çµæœä¿æŒç”¨è¾æ›¸
        self.results = dict()
        # è¨­å®šå€¤
        self.total_timesteps = 100_000

    def train(self, df: pd.DataFrame, path_model: str, log_dir: str, new_model: bool = False):
        # å‡ºåŠ›å½¢å¼ã‚’æŒ‡å®š
        custom_logger = configure(log_dir, ["stdout", "csv", "tensorboard"])

        # å­¦ç¿’ç’°å¢ƒã®å–å¾—
        self.env = env = TrainingEnv(df)
        # å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        if not new_model and os.path.exists(path_model):
            print(f"ãƒ¢ãƒ‡ãƒ« {path_model} ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
            try:
                model = MaskablePPO.load(path_model, env, verbose=1)
            except ValueError:
                print("èª­ã¿è¾¼ã¿æ™‚ã€ä¾‹å¤– ValueError ãŒç™ºç”Ÿã—ãŸã®ã§æ–°è¦ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚")
                model = MaskablePPO("MlpPolicy", env, verbose=1)
        else:
            print(f"æ–°è¦ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚")
            model = MaskablePPO("MlpPolicy", env, verbose=1)

        # ãƒ­ã‚¬ãƒ¼ã‚’å·®ã—æ›¿ãˆ
        model.set_logger(custom_logger)

        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        model.learn(total_timesteps=self.total_timesteps)

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {path_model} ã«ä¿å­˜ã—ã¾ã™ã€‚")
        model.save(path_model)

        # å­¦ç¿’ç’°å¢ƒã®è§£æ”¾
        env.close()

    def infer(self, df: pd.DataFrame, path_model: str, flag_all: bool = False) -> bool:
        # å­¦ç¿’ç’°å¢ƒã®å–å¾—
        self.env = env = TrainingEnv(df)

        # å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        if os.path.exists(path_model):
            print(f"ãƒ¢ãƒ‡ãƒ« {path_model} ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
        else:
            print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {path_model} ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return False
        try:
            model = MaskablePPO.load(path_model, env, verbose=1)
        except ValueError as e:
            print(e)
            return False

        self.results["obs"] = list()
        self.results["reward"] = list()
        obs, _ = env.reset()
        terminated = False
        truncated = False
        while not (terminated or truncated):
            action_masks = env.action_masks()
            action, _states = model.predict(obs, action_masks=action_masks)
            obs, reward, terminated, truncated, info = env.step(action)
            # è¦³æ¸¬å€¤ãƒˆãƒ¬ãƒ³ãƒ‰æˆç”¨
            self.results["obs"].append(obs)
            # å ±é…¬åˆ†å¸ƒä½œæˆç”¨
            self.results["reward"].append(reward)

        # å–å¼•å†…å®¹
        self.results["transaction"] = env.getTransaction()

        # å­¦ç¿’ç’°å¢ƒã®è§£æ”¾
        env.close()

        return True


class WorkerAgentSB3(QObject):
    completedResetEnv = Signal()
    completedTrading = Signal()
    notifyAction = Signal(int, PositionType)  # å£²è²·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€šçŸ¥
    readyNext = Signal()
    sendResults = Signal(dict)

    def __init__(self, path_model: str, autopilot: bool):
        super().__init__()
        self.logger = logging.getLogger(__name__)
        self.obs = None
        self.done = False
        self.autopilot = autopilot

        # å­¦ç¿’ç’°å¢ƒã®å–å¾—
        self.env = env = TradingEnv()
        # å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        self.logger.info(f"{__name__}: model, {path_model} is used.")
        self.model = MaskablePPO.load(path_model, env)

    @Slot(float, float, float)
    def addData(self, ts: float, price: float, volume: float):
        if self.done:
            # å–å¼•çµ‚äº†ï¼ˆå¿µã®ç‚ºï¼‰
            self.completedTrading.emit()
        else:
            # ãƒ†ã‚£ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦³æ¸¬å€¤ã‚’å–å¾—
            obs = self.env.getObservation(ts, price, volume)
            # ç¾åœ¨ã®è¡Œå‹•ãƒã‚¹ã‚¯ã‚’å–å¾—
            masks = self.env.action_masks()
            # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è¡Œå‹•äºˆæ¸¬
            action, _states = self.model.predict(obs, action_masks=masks)

            # self.autopilot ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ã‚Œã°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’é€šçŸ¥
            if self.autopilot:
                position: PositionType = self.env.reward_man.position
                if ActionType(action) != ActionType.HOLD:
                    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                    # å£²è²·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€šçŸ¥ã™ã‚‹ã‚·ã‚°ãƒŠãƒ«ï¼ˆHOLD ã®æ™‚ã¯é€šçŸ¥ã—ãªã„ï¼‰
                    self.notifyAction.emit(action, position)
                    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++

            # -----------------------------------------------------------------
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ç’°å¢ƒã®çŠ¶æ…‹æ›´æ–°
            # ã€æ³¨æ„ã€‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ç’°å¢ƒã§ã¯ step ãƒ¡ã‚½ãƒƒãƒ‰ã§è¦³æ¸¬å€¤ã¯è¿”ã•ã‚Œãªã„
            # -----------------------------------------------------------------
            reward, terminated, truncated, info = self.env.step(action)
            if terminated or truncated:
                self.done = True
                # å–å¼•çµ‚äº†
                self.completedTrading.emit()
            else:
                # æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å—ã‘å…¥ã‚Œæº–å‚™å®Œäº†
                self.readyNext.emit()

    def postProcs(self):
        dict_result = dict()
        dict_result["transaction"] = self.env.getTransaction()
        self.sendResults.emit(dict_result)

    @Slot()
    def resetEnv(self):
        # ç’°å¢ƒã®ãƒªã‚»ãƒƒãƒˆ
        self.obs, _ = self.env.reset()
        self.done = False
        self.completedResetEnv.emit()

    @Slot(bool)
    def setAutoPilotStatus(self, state: bool):
        self.autopilot = state
        self.logger.info(f"{__name__}: autopilot is set to {state}.")


class WorkerAgent(QObject):
    """
    å¼·åŒ–å­¦ç¿’ã‚’åˆ©ç”¨ã›ãšã«ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã¿ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    completedResetEnv = Signal()
    completedTrading = Signal()
    notifyAction = Signal(int, PositionType)  # å£²è²·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€šçŸ¥
    readyNext = Signal()
    sendObs = Signal(pd.DataFrame)
    sendParams = Signal(dict)
    sendResults = Signal(dict)
    sendTechnicals = Signal(dict)

    def __init__(self, autopilot: bool, code: str, dict_param: dict):
        super().__init__()
        self.logger = logging.getLogger(__name__)
        self.autopilot = autopilot

        self.obs = None
        self.done = False

        self.list_obs = list()
        self.df_obs = None

        # å­¦ç¿’ç’°å¢ƒã®å–å¾—
        self.env = TradingEnv(code, dict_param)

        # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        self.model = AlgoTrade(self.list_obs)

    @Slot(float, float, float)
    def addData(self, ts: float, price: float, volume: float):
        if self.done:
            # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
            # ğŸ§¿ å–å¼•çµ‚äº†ï¼ˆå¿µã®ç‚ºï¼‰
            self.completedTrading.emit()
            # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
        else:
            # ãƒ†ã‚£ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¸è¿½åŠ 
            row = len(self.df_obs)
            self.df_obs.at[row, "Timestamp"] = ts
            self.df_obs.at[row, "Price"] = price
            self.df_obs.at[row, "Volume"] = volume
            # ãƒ†ã‚£ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦³æ¸¬å€¤ã‚’å–å¾—
            obs = self.env.getObservation(ts, price, volume)
            # ç¾åœ¨ã®è¡Œå‹•ãƒã‚¹ã‚¯ã‚’å–å¾—
            masks = self.env.action_masks()
            # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è¡Œå‹•äºˆæ¸¬
            action, _states = self.model.predict(obs, action_masks=masks)
            # self.autopilot ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ã‚Œã°ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’é€šçŸ¥
            if self.autopilot:
                position: PositionType = self.env.getCurrentPosition()
                if ActionType(action) != ActionType.HOLD:
                    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                    # ğŸ§¿ å£²è²·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€šçŸ¥ã™ã‚‹ã‚·ã‚°ãƒŠãƒ«ï¼ˆHOLD ã®æ™‚ã¯é€šçŸ¥ã—ãªã„ï¼‰
                    self.notifyAction.emit(action, position)
                    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++

            # -----------------------------------------------------------------
            # ãƒ—ãƒ­ãƒƒãƒˆç”¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
            dict_tech = {"ts": ts, "ma_1": float(obs[0]), "ma_2": float(obs[1])}
            # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
            # ğŸ§¿ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’é€šçŸ¥ã™ã‚‹ã‚·ã‚°ãƒŠãƒ«
            self.sendTechnicals.emit(dict_tech)
            # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

            # -----------------------------------------------------------------
            # obs ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¸è¿½åŠ 
            for col, val in zip(self.list_obs, obs):
                self.df_obs.at[row, col] = val
            # -----------------------------------------------------------------
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ç’°å¢ƒã®çŠ¶æ…‹æ›´æ–°
            # ã€æ³¨æ„ã€‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ç’°å¢ƒã§ã¯ step ãƒ¡ã‚½ãƒƒãƒ‰ã§è¦³æ¸¬å€¤ã¯è¿”ã•ã‚Œãªã„
            # -----------------------------------------------------------------
            reward, terminated, truncated, info = self.env.step(action)
            if terminated:
                print("terminated ãƒ•ãƒ©ã‚°ãŒç«‹ã¡ã¾ã—ãŸã€‚")
                self.done = True
                # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                # ğŸ§¿ å–å¼•çµ‚äº†
                self.completedTrading.emit()
                # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
            elif truncated:
                print("truncated ãƒ•ãƒ©ã‚°ãŒç«‹ã¡ã¾ã—ãŸã€‚")
                self.done = True
                # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                # ğŸ§¿ å–å¼•çµ‚äº†
                self.completedTrading.emit()
                # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
            else:
                # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                # ğŸ§¿ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å—ã‘å…¥ã‚Œæº–å‚™å®Œäº†
                self.readyNext.emit()
                # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

    @Slot()
    def forceRepay(self):
        self.env.forceRepay()

    @Slot()
    def getObs(self):
        self.sendObs.emit(self.df_obs)

    @Slot()
    def getParams(self):
        dict_param = self.env.getParams()
        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        self.sendParams.emit(dict_param)

    @Slot()
    def postProcs(self):
        dict_result = dict()
        dict_result["transaction"] = self.env.getTransaction()
        self.sendResults.emit(dict_result)

    @Slot()
    def resetEnv(self):
        # ç’°å¢ƒã®ãƒªã‚»ãƒƒãƒˆ
        self.obs, _ = self.env.reset()
        self.done = False

        list_colname = ["Timestamp", "Price", "Volume"]
        self.list_obs.clear()
        self.list_obs.extend(self.env.getObsList())
        list_colname.extend(self.list_obs)
        dict_colname = dict()
        for colname in list_colname:
            dict_colname[colname] = []
        self.df_obs = pd.DataFrame(dict_colname)
        # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
        # ğŸ§¿ ç’°å¢ƒã®ãƒªã‚»ãƒƒãƒˆç’°å¢ƒã‚’é€šçŸ¥
        self.completedResetEnv.emit()
        # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

    @Slot(bool)
    def setAutoPilotStatus(self, state: bool):
        self.autopilot = state
        self.logger.info(f"{__name__}: autopilot is set to {state}.")
